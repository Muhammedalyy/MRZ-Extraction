{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Au8V8pG3OHgs"
   },
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import matplotlib.pyplot as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRfPJrVml0kA"
   },
   "source": [
    "# Reading the Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 957
    },
    "id": "98Li0KqmkplV",
    "outputId": "c6dfd9ef-e6d3-4728-8252-17fdd929f2a1"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"0.jpg\")\n",
    "\n",
    "cv2.imshow(\"\",image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5c1JURnl8Ah"
   },
   "source": [
    "# Extracting the Passport from the Background\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ddefIZHw8jg9",
    "outputId": "8ae15522-bfba-46be-a74a-2cf66244c349"
   },
   "outputs": [],
   "source": [
    "# loop over the contours\n",
    "b=0 # i am using this variable as a boolean, if the right contour is found then it will equal to 1 if not then it stays as Zero\n",
    "rec=250\n",
    "for i in range(0,4):  # this loop is to checks the image from 4 different perspective by flipping it 4 time as the passport in the image my be flipped, so we need to correct that\n",
    "\n",
    "    rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (rec, rec))  \n",
    "    # here we treated the rect as a square as the target outout's shape (Passport) will most likely be colse to a square\n",
    "    sqKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (200, 200))  # sqKernel is used to fill the gap between the 2 sentences we want to extract(MRZ)\n",
    "    image = imutils.resize(image, height=600)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, rectKernel)\n",
    "    gradX = cv2.Sobel(blackhat, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)\n",
    "    gradX = np.absolute(gradX)\n",
    "    (minVal, maxVal) = (np.min(gradX), np.max(gradX))\n",
    "    gradX = (255 * ((gradX - minVal) / (maxVal - minVal))).astype(\"uint8\")\n",
    "    gradX = cv2.morphologyEx(gradX, cv2.MORPH_CLOSE, rectKernel)\n",
    "    thresh = cv2.threshold(gradX, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, sqKernel)\n",
    "    thresh = cv2.erode(thresh, None, iterations=4)\n",
    "    p = int(image.shape[1] * 0.05)\n",
    "    thresh[:, 0:p] = 0\n",
    "    thresh[:, image.shape[1] - p:] = 0\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "              cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "    for c in cnts:\n",
    "            # compute the bounding box of the contour and use the contour to\n",
    "            # compute the aspect ratio and coverage ratio of the bounding box\n",
    "            # width to the width of the image\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            ar = w / float(h)\n",
    "            crWidth = w / float(gray.shape[1])\n",
    "            # check to see if the aspect ratio and coverage width are within\n",
    "            # acceptable criteria\n",
    "            if ar > 0 and crWidth > 0.6 : \n",
    "\n",
    "              # extract the ROI from the image and draw a bounding box\n",
    "              # surrounding the MRZ\n",
    "                passport = image[y:y + h, x:x + w].copy()\n",
    "                #cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                b=1\n",
    "                break\n",
    "    if b==1: break\n",
    "    if b == 0: # that means we didn't find the right contour, and we might need to flipp the image and start all over again\n",
    "              image = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "   \n",
    "# show  images\n",
    "cv2.imshow(\"The Original Image\",image)\n",
    "cv2.imshow(\"Passport\",passport)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcDhEs-amuKa"
   },
   "source": [
    "# Expanding the ROI\n",
    "There is a chance that the algorithm may cut a small wanted details from the passport when extracting it. So, \"expandingROI\" function here tries to decrease this chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "6PL-ip_RbANb",
    "outputId": "cadedd2a-5b24-4953-ae36-8d298b421c25"
   },
   "outputs": [],
   "source": [
    "   # I wanted to increase the width by 32 degree from both sides, and the height by just 8 degrees\n",
    "  # This function here makes sure that I am not going out of the boundries of the image\n",
    "def expandingROI(image,x,y,w,h,increasingWidhParameter,increasingHeightParameter):\n",
    "    x1=x\n",
    "    x2=x+w\n",
    "    y1=y\n",
    "    y2=y+h\n",
    "    for i in range (0,4):  \n",
    "        if x1>=increasingWidhParameter:        \n",
    "              x1=x1-increasingWidhParameter\n",
    "        if x2+increasingWidhParameter<image.shape[1]:\n",
    "              x2=x2+increasingWidhParameter\n",
    "        if y1>=increasingHeightParameter:\n",
    "              y1=y1-increasingHeightParameter\n",
    "        if y2+increasingHeightParameter< image.shape[0]:\n",
    "              y2=y2+increasingHeightParameter\n",
    "    ROI = image[y1:y2, x1:x2].copy()\n",
    "    return ROI\n",
    "\n",
    "passport= expandingROI(image,x,y,w,h,6,2)\n",
    "\n",
    "cv2.imshow(\"ROI\",passport)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWNH93Cfn4a9"
   },
   "source": [
    "# Visualizing the Result with Clustering Segmentation with Kmeans \n",
    " Here I wanted to Visualize how well the passport is separated from the background and also do some sort of threshold to help in the next phase when extractin the MRZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "W88QmPEsCHBJ",
    "outputId": "affbb118-a600-4bb5-9e16-6fb45ba296f9"
   },
   "outputs": [],
   "source": [
    "segmentedImage= passport.copy()\n",
    "temp = cv2.cvtColor(segmentedImage, cv2.COLOR_BGR2RGB)\n",
    "pixel_values = temp.reshape((-1, 3))\n",
    "# convert to float\n",
    "pixel_values = np.float32(pixel_values)\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 500, 0.2)\n",
    "k = 2\n",
    "_, labels, (centers) = cv2.kmeans(pixel_values, k, None, criteria, 20, cv2.KMEANS_RANDOM_CENTERS)\n",
    "centers = np.uint8(centers)\n",
    "\n",
    "# flatten the labels array\n",
    "labels = labels.flatten()\n",
    "cntr0=0\n",
    "cntr1=0\n",
    "for k in range(len(labels)):   # here i am trying to figure out wich label is the dominant assuming that it has to be the passport to then remove the other label from the image\n",
    "    if labels[k]==0:\n",
    "        cntr0+=1\n",
    "    else:\n",
    "        cntr1+=1\n",
    "segmented_image = centers[labels.flatten()]\n",
    "segmented_image = segmented_image.reshape(segmentedImage.shape)\n",
    "masked_image = np.copy(segmentedImage)\n",
    "# convert to the shape of a vector of pixel values\n",
    "masked_image = masked_image.reshape((-1, 3))\n",
    "# color (i.e cluster) to disable\n",
    "cluster = 0\n",
    "if cntr0> cntr1: cluster= 1\n",
    "else: cluster = 0\n",
    "masked_image[labels == cluster] = [0, 0, 0]\n",
    "masked_image = masked_image.reshape(segmentedImage.shape)\n",
    "\n",
    "\n",
    "# show the image\n",
    "cv2.imshow('Segmanted Image',masked_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the MRZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 688
    },
    "id": "oIPMGmoQMb_k",
    "outputId": "65829997-4c0d-4f55-9664-109d82be5ad2"
   },
   "outputs": [],
   "source": [
    "# loop over the contours\n",
    "b=0 # i am using this variable as a boolean, if the right contour is found then it will equal to 1 if not then it stays as Zero\n",
    "recWidth=32\n",
    "recHeight=15\n",
    "sq=25\n",
    "image=masked_image\n",
    "for j in range(0,7):  #this loop is basically for trying different sizes for the kernels to tune it so we be able to extract the right Contour\n",
    "  for i in range(0,4):  # this loop is to checks the image from 4 different perspective by flipping it 4 time as the passport in the image my be flipped, so we need to correct that\n",
    "      rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (recWidth, recHeight))\n",
    "      sqKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (sq, sq))\n",
    "      image = imutils.resize(image, height=600)\n",
    "      passport = imutils.resize(passport, height=600)\n",
    "      gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "      gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "      blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, rectKernel)\n",
    "      gradX = cv2.Sobel(blackhat, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)\n",
    "      gradX = np.absolute(gradX)\n",
    "      (minVal, maxVal) = (np.min(gradX), np.max(gradX))\n",
    "      gradX = (255 * ((gradX - minVal) / (maxVal - minVal))).astype(\"uint8\")\n",
    "      gradX = cv2.morphologyEx(gradX, cv2.MORPH_CLOSE, rectKernel)\n",
    "      thresh = cv2.threshold(gradX, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "      thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, sqKernel)\n",
    "      thresh = cv2.erode(thresh, None, iterations=4)\n",
    "      p = int(image.shape[1] * 0.05)\n",
    "      thresh[:, 0:p] = 0\n",
    "      thresh[:, image.shape[1] - p:] = 0\n",
    "      cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "                cv2.CHAIN_APPROX_SIMPLE)\n",
    "      cnts = imutils.grab_contours(cnts)\n",
    "      cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "      for c in cnts:\n",
    "              # compute the bounding box of the contour and use the contour to\n",
    "              # compute the aspect ratio and coverage ratio of the bounding box\n",
    "              # width to the width of the image\n",
    "              (x, y, w, h) = cv2.boundingRect(c)\n",
    "              ar = w / float(h)\n",
    "              crWidth = w / float(gray.shape[1])\n",
    "              width=w\n",
    "              height=h\n",
    "              # check to see if the aspect ratio and coverage width are within\n",
    "              # acceptable criteria\n",
    "            # if the height is too big we need to decrease the width of the rectangle kernel to extract smaller contours\n",
    "              if h>=150 and recWidth >5:\n",
    "                recWidth= recWidth-5\n",
    "                continue\n",
    "              if ar > 2 and crWidth > 0.5 :\n",
    "                # pad the bounding box since we applied erosions and now need\n",
    "                # to re-grow it\n",
    "                  pX = int((x + w) * 0.03)\n",
    "                  pY = int((y + h) * 0.03)\n",
    "                  (x, y) = (x - pX, y - pY)\n",
    "                  (w, h) = (w + (pX * 2), h + (pY * 2))\n",
    "\n",
    "                # extract the ROI from the image and draw a bounding box\n",
    "                  roi= expandingROI(passport,x,y,w,h,3,1)\n",
    "\n",
    "                  #cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "                  b=1\n",
    "                  break\n",
    "      if b==1: break\n",
    "\n",
    "      if b == 0:  # that means we didn't find the right contour, and we might need to flipp the image\n",
    "                image = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "                passport = cv2.rotate(passport, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "  if width>= 12*height:    # if the width is so much bigger than the height that means we need to start all over again\n",
    "                                         # as our square kernel needs to be bigger to fill the gaps between the 2 sentences\n",
    "                  sq=sq+5\n",
    "  else: break\n",
    "\n",
    "\n",
    "   \n",
    "cv2.imshow(\"\",image)\n",
    "cv2.imshow(\"MRZ\",roi)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the MRZ\n",
    "for this phase, I have used OCR (pytesseract) to read the MRZ and extract it as a text file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5, 5), np.uint8)\n",
    "dilated =cv2.dilate(roi, kernel, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont=cv2.convertScaleAbs(roi, 12, 1)\n",
    "gray=cv2.cvtColor(cont,cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(gray, 0, 255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j PEAUSC ETI ZEWK< SANE C \n",
      " PE09 15986 14584060771 1903278< 406009 96K< <<< 04\n"
     ]
    }
   ],
   "source": [
    "text=pytesseract.image_to_string(thresh,config='--psm 6')\n",
    "text =text.split('\\n')\n",
    "print(text[0][0:25],'\\n',text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"MRZ\",roi)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E PSAUSCITIZENK< JANE <<  \n",
      " PE09159861AUS8406077F 1903278<40600996K<<<<0%\n"
     ]
    }
   ],
   "source": [
    "text=pytesseract.image_to_string(roi\n",
    "                                 ,config='--psm 6')\n",
    "text =text.split('\\n')\n",
    "print(text[0][0:25],'\\n',text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "textFile = open('sample2.txt', 'a')\n",
    "textFile.write(text[0][0:25]+'\\n'+text[1])\n",
    "textFile.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
